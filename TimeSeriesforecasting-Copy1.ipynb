{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Develop ML Models for Human Activity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity Recognition Using Smartphones Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human Activity Recognition, or HAR for short, is the problem of predicting what a person is\n",
    "doing based on a trace of their movement using sensors. \n",
    "\n",
    "A standard human activity recognition dataset is the Activity Recognition Using Smartphones made available in 2012. The data is provided as a single zip file that is about 58 megabytes in size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "\t# load input data\n",
    "\tX = load_file(prefix + group + '/X_'+group+'.txt')\n",
    "\t# load class output\n",
    "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "\t# load all train\n",
    "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset1/HARDataset/')\n",
    "\t# load all test\n",
    "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset1/HARDataset/')\n",
    "\t# flatten y\n",
    "\ttrainy, testy = trainy[:,0], testy[:,0]\n",
    "\treturn trainX, trainy, testX, testy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can define a list of machine learning models to evaluate on this problem.\n",
    "\n",
    "We will evaluate the models using default configurations. We are not looking for optimal configurations\n",
    "of these models at this point, just a general idea of how well sophisticated models with default\n",
    "configurations perform on this problem. We will evaluate a diverse set of nonlinear and ensemble\n",
    "machine learning algorithms, specifically:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nonlinear Algorithms**:\n",
    "\n",
    "* k-Nearest Neighbors\n",
    "* Classification and Regression Tree\n",
    "* Support Vector Machine\n",
    "* Naive Bayes\n",
    "\n",
    "**Ensemble Algorithms**:\n",
    "\n",
    "* Bagged Decision Trees\n",
    "* Random Forest\n",
    "* Extra Trees\n",
    "* Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the models and store them in a dictionary that maps the model object to a\n",
    "short name that will help in analyzing the results. The define models() function below defines\n",
    "the eight models that we will evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict of standard models to evaluate {name:object}\n",
    "def define_models(models=dict()):\n",
    "# nonlinear models\n",
    "  models['knn'] = KNeighborsClassifier(n_neighbors=7)\n",
    "  models['cart'] = DecisionTreeClassifier()\n",
    "  models['svm'] = SVC()\n",
    "  models['bayes'] = GaussianNB()\n",
    "# ensemble models\n",
    "  models['bag'] = BaggingClassifier(n_estimators=100)\n",
    "  models['rf'] = RandomForestClassifier(n_estimators=100)\n",
    "  models['et'] = ExtraTreesClassifier(n_estimators=100)\n",
    "  models['gbm'] = GradientBoostingClassifier(n_estimators=100)\n",
    "  print('Defined %d models' % len(models))\n",
    "  return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is quite extensible and you can easily update to define any machine learning\n",
    "models or model configurations you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Models**\n",
    "\n",
    "The next step is to evaluate the defined models in the loaded dataset. \n",
    "\n",
    "This step is divided into the evaluation of a single model and the evaluation of all of the models. We will evaluate a single model by first fitting it on the training dataset, making a prediction on the test dataset, and then evaluating the prediction using a metric. In this case we will use classification accuracy that will capture the performance (or error) of a model given the balance observations across\n",
    "the six activities (or classes). The evaluate model() function below implements this behavior,\n",
    "evaluating a given model and returning the classification accuracy as a percentage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "  # fit the model\n",
    "  model.fit(trainX, trainy)\n",
    "  # make predictions\n",
    "  yhat = model.predict(testX)\n",
    "  # evaluate predictions\n",
    "  accuracy = accuracy_score(testy, yhat)\n",
    "  return accuracy * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now call the evaluate model() function repeatedly for each of the defined model.\n",
    "The evaluate models() function below implements this behavior, taking the dictionary of\n",
    "defined models, and returns a dictionary of model names mapped to their classification accuracy.\n",
    "\n",
    "Because the evaluation of the models may take a few minutes, the function prints the performance\n",
    "of each model after it is evaluated as some verbose feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(trainX, trainy, testX, testy, models):\n",
    "  results = dict()\n",
    "  for name, model in models.items():\n",
    "   # evaluate the model\n",
    "   results[name] = evaluate_model(trainX, trainy, testX, testy, model)\n",
    "   # show process\n",
    "   print('>%s: %.3f' % (name, results[name]))\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to summarize the findings. We can sort all of the results by the classification\n",
    "accuracy in descending order because we are interested in maximizing accuracy. The results\n",
    "of the evaluated models can then be printed, clearly showing the relative rank of each of the\n",
    "evaluated models. The summarize results() function below implements this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and plot the results\n",
    "def summarize_results(results, maximize=True):\n",
    "\t# create a list of (name, mean(scores)) tuples\n",
    "\tmean_scores = [(k,v) for k,v in results.items()]\n",
    "\t# sort tuples by mean score\n",
    "\tmean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "\t# reverse for descending order (e.g. for accuracy)\n",
    "\tif maximize:\n",
    "\t\tmean_scores = list(reversed(mean_scores))\n",
    "\tprint()\n",
    "\tfor name, score in mean_scores:\n",
    "\t\tprint('Name=%s, Score=%.3f' % (name, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 8 models\n",
      ">knn: 90.329\n",
      ">cart: 85.646\n",
      ">svm: 95.046\n",
      ">bayes: 77.027\n",
      ">bag: 90.193\n",
      ">rf: 92.399\n",
      ">et: 93.892\n",
      ">gbm: 93.756\n",
      "\n",
      "Name=svm, Score=95.046\n",
      "Name=et, Score=93.892\n",
      "Name=gbm, Score=93.756\n",
      "Name=rf, Score=92.399\n",
      "Name=knn, Score=90.329\n",
      "Name=bag, Score=90.193\n",
      "Name=cart, Score=85.646\n",
      "Name=bayes, Score=77.027\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "trainX, trainy, testX, testy = load_dataset()\n",
    "# get model list\n",
    "models = define_models()\n",
    "# evaluate models\n",
    "results = evaluate_models(trainX, trainy, testX, testy, models)\n",
    "# summarize results\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first loads the train and test datasets. The eight models are then\n",
    "evaluated in turn, printing the performance for each. Finally, a rank of the models by their\n",
    "performance on the test set is displayed. We can see that both the ExtraTrees ensemble method\n",
    "and the Support Vector Machines nonlinear methods achieve a performance of about 94%\n",
    "accuracy on the test set. This is a great result, exceeding the reported 89% by SVM in the\n",
    "original paper.\n",
    "\n",
    "Note: Given the stochastic nature of the algorithm, your specific results may vary. Consider\n",
    "running the example a few times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These results show what is possible given domain expertise in the preparation of the data and\n",
    "the engineering of domain-specific features**. As such, these results can be taken as a performance\n",
    "upper-bound of what could be pursued through more advanced methods that **may be able to\n",
    "automatically learn features as part of fitting the model, such as deep learning methods**. \n",
    "\n",
    "Any such advanced methods would be fit and evaluated on the raw data from which the engineered\n",
    "features were derived. And as such, the performance of machine learning algorithms evaluated\n",
    "on that data directly may provide an expected lower bound on the performance of any more\n",
    "advanced methods. We will explore this in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Develop CNNs for Human Activity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will develop a one-dimensional convolutional neural network model (1D\n",
    "CNN) for the human activity recognition dataset. **Convolutional neural network models were\n",
    "developed for image classification problems**, where the model learns an internal representation\n",
    "of a two-dimensional input, in a process referred to as feature learning. \n",
    "\n",
    "Although we refer to the model as 1D, **it supports multiple dimensions of input as separate channels**, like the color channels of an image (red, green and blue). This same process can be harnessed on\n",
    "**one-dimensional sequences of data**, such as in the case of acceleration and gyroscopic data for\n",
    "human activity recognition. The model **learns to extract features from sequences of observations\n",
    "and how to map the internal features to different activity types**. \n",
    "\n",
    "The benefit of using CNNs for sequence classification is that **they can learn from the raw\n",
    "time series data directly**, and in turn **do not require domain expertise to manually engineer\n",
    "input features**. The model can learn an internal representation of the time series data and\n",
    "ideally achieve comparable performance to models fit on a version of the dataset with engineered\n",
    "features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human activity recognition is the problem of classifying sequences of accelerometer data\n",
    "recorded by specialized harnesses or smartphones into known well-defined movements.\n",
    "\n",
    "**Classical\n",
    "approaches** to the problem involve **hand crafting features from the time series data based on\n",
    "fixed-sized windows and training machine learning models, such as ensembles of decision trees**.\n",
    "The difficulty is that this feature engineering requires deep expertise in the field.\n",
    "\n",
    "Recently, deep learning methods such as recurrent neural networks and one-dimensional convolutional neural networks, or CNNs, have been shown to provide state-of-the-art results on challenging activity\n",
    "recognition tasks with little or no data feature engineering, instead using feature learning on raw\n",
    "data. In this tutorial, you will discover how to develop one-dimensional convolutional neural\n",
    "networks for time series classification on the problem of human activity recognition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topics we will treat in this case are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to load and prepare the data for a standard human activity recognition dataset and\n",
    "develop a single 1D CNN model that achieves excellent performance on the raw data:\n",
    "\n",
    "* How to further tune the performance of the model, including data transformation, filter\n",
    "maps, and kernel sizes.\n",
    "* How to develop a sophisticated multi-headed one-dimensional convolutional neural network\n",
    "model that provides an ensemble-like result.\n",
    "\n",
    "\n",
    "Let’s get started.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load the raw dataset into memory.\n",
    "\n",
    "There are three main signal types in the raw data: total acceleration, body acceleration, and body gyroscope. Each has three axes of data. This means that there are a total of nine variables for each time step. \n",
    "\n",
    "Further, each series of data has been partitioned into overlapping windows of 2.65 seconds of data,or 128 time steps.These windows of data correspond to the windows of engineered features (rows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that one row of data has (128 × 9), or 1,152, elements. \n",
    "\n",
    "It is likely that there is some redundant data. The signals are stored in the /Inertial Signals/ directory under the train and test subdirectories. Each axis of each signal is stored in a separate file, meaning that each of the train and test datasets have nine input files to load and one output file to load.\n",
    "\n",
    "We can batch the loading of these files into groups given the consistent directory structures\n",
    "and file naming conventions. The input data is in CSV format where columns are separated by\n",
    "whitespace. Each of these files can be loaded as a NumPy array. The load file() function\n",
    "below loads a dataset given the file path to the file and returns the loaded data as a NumPy\n",
    "array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then load all data for a given group (train or test) into a single three-dimensional\n",
    "NumPy array, where the dimensions of the array are [samples, timesteps, features]. To\n",
    "make this clearer, there are 128 time steps and nine features, where the number of samples is the\n",
    "number of rows in any given raw signal data file. The load group() function below implements\n",
    "this behavior. The dstack() NumPy function allows us to stack each of the loaded 3D arrays\n",
    "into a single 3D array where the variables are separated on the third dimension (features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a list of files into a 3D array of [samples, timesteps, features]\n",
    "def load_group(filenames, prefix=''):\n",
    "\tloaded = list()\n",
    "\tfor name in filenames:\n",
    "\t\tdata = load_file(prefix + name)\n",
    "\t\tloaded.append(data)\n",
    "\t# stack group so that features are the 3rd dimension\n",
    "\tloaded = dstack(loaded)\n",
    "\treturn loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this function to load all input signal data for a given group, such as train or test.\n",
    "The load dataset group() function below loads all input signal data and the output data for\n",
    "a single group using the consistent naming conventions between the train and test directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "\tfilepath = prefix + group + '/Inertial Signals/'\n",
    "\t# load all 9 files as a single array\n",
    "\tfilenames = list()\n",
    "\t# total acceleration\n",
    "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "\t# body acceleration\n",
    "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "\t# body gyroscope\n",
    "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "\t# load input data\n",
    "\tX = load_group(filenames, filepath)\n",
    "\t# load class output\n",
    "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can load each of the train and test datasets. The output data is defined as an\n",
    "integer for the class number. We must one hot encode these class integers so that the data is\n",
    "suitable for fitting a neural network multiclass classification model. We can do this by calling\n",
    "the to categorical() Keras function. The load dataset() function below implements this\n",
    "behavior and returns the train and test X and y elements ready for fitting and evaluating the\n",
    "defined models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "\t# load all train\n",
    "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset1/HARDataset/')\n",
    "\t# load all test\n",
    "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset1/HARDataset/')\n",
    "\t# zero-offset class values\n",
    "\ttrainy = trainy - 1\n",
    "\ttesty = testy - 1\n",
    "\t# one hot encode y\n",
    "\ttrainy = to_categorical(trainy)\n",
    "\ttesty = to_categorical(testy)\n",
    "\treturn trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data loaded into memory ready for modeling, **we can define, fit, and\n",
    "evaluate a 1D CNN model**. We can define a function named evaluate model() that takes the\n",
    "train and test dataset, fits a model on the training dataset, evaluates it on the test dataset, and\n",
    "returns an estimate of the model’s performance. First, we must define the CNN model using\n",
    "the Keras deep learning library. The model requires a three-dimensional input with [samples,\n",
    "timesteps, features].\n",
    "\n",
    "This is exactly how we have loaded the data, where **one sample is one window of the time\n",
    "series data, each window has 128 time steps, and a time step has nine variables or features**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The output for the model will be a six-element vector containing the probability of a given window\n",
    "belonging to each of the six activity types**. These input and output dimensions are required\n",
    "when fitting the model, and we can extract them from the provided training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is defined as a Sequential Keras model, for simplicity. We will define the model\n",
    "as having two 1D CNN layers, followed by a dropout layer for regularization, then a pooling\n",
    "layer. \n",
    "\n",
    "It is common to define CNN layers in groups of two in order to give the model a good\n",
    "chance of learning features from the input data. CNNs learn very quickly, so the **dropout layer**\n",
    "is intended to help slow down the learning process and hopefully result in a better final model.\n",
    "**The pooling layer** reduces the learned features to their size, consolidating them to only the\n",
    "most essential elements. After the CNN and pooling, **the learned features are flattened to one\n",
    "long vector and pass through a fully connected layer before the output layer used to make a\n",
    "prediction**. \n",
    "\n",
    "\n",
    "**The fully connected layer** ideally provides a buffer between the learned features and\n",
    "the output with the intent of interpreting the learned features before making a prediction.\n",
    "\n",
    "For this model, we will use a standard configuration of 64 parallel feature maps and a kernel\n",
    "size of 3. \n",
    "\n",
    "**The feature maps are the number of times the input is processed or interpreted**,\n",
    "whereas the **kernel size is the number of input time steps considered as the input sequence is\n",
    "read or processed onto the feature maps**. The efficient Adam version of **stochastic gradient\n",
    "descent** will be used to optimize the network, and the **categorical cross-entropy loss function**\n",
    "will be used given that we are learning a multiclass classification problem. \n",
    "\n",
    "The definition of the model is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "\tverbose, epochs, batch_size = 0, 10, 32\n",
    "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv1D(64, 3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "\tmodel.add(Conv1D(64, 3, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(MaxPooling1D())\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is fit for a fixed number of epochs, in this case 10, and a batch size of 32 samples\n",
    "will be used, where 32 windows of data will be exposed to the model before the weights of the\n",
    "model are updated. \n",
    "\n",
    "Once the model is fit, it is evaluated on the test dataset and the accuracy\n",
    "of the fit model on the test dataset is returned. The complete evaluate model() function is\n",
    "listed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is nothing special about the network structure or chosen hyperparameters; they are\n",
    "just a starting point for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize scores\n",
    "\n",
    "We can summarize the sample of scores by calculating and reporting **the mean and standard\n",
    "deviation of the performance**. \n",
    "\n",
    "The mean gives the average accuracy of the model on the dataset, whereas the standard deviation gives the average variance of the accuracy from the mean. The function summarize results() below summarizes the results of a run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "\n",
    "def summarize_results(scores):\n",
    "\tprint(scores)\n",
    "\tm, s = mean(scores), std(scores)\n",
    "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "    \n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "\t# load data\n",
    "\ttrainX, trainy, testX, testy = load_dataset()\n",
    "\t# repeat experiment\n",
    "\tscores = list()\n",
    "\tfor r in range(repeats):\n",
    "\t\tscore = evaluate_model(trainX, trainy, testX, testy)\n",
    "\t\tscore = score * 100.0\n",
    "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
    "\t\tscores.append(score)\n",
    "\t# summarize results\n",
    "\tsummarize_results(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can bundle up the repeated evaluation, gathering of results, and summarization of results\n",
    "into a main function for the experiment, called run experiment(), listed below. \n",
    "\n",
    "By default, the model is evaluated 10 times before the performance of the model is reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot judge the skill of the model from a single evaluation. The reason for this is that\n",
    "**neural networks are stochasti**c, meaning that a different specific model will result when training\n",
    "the same model configuration on the same data. \n",
    "\n",
    "This is a feature of the network in that it gives the model its adaptive ability, but requires a slightly more complicated evaluation of the model.\n",
    "\n",
    "We will repeat the evaluation of the model multiple times, then summarize the performance of\n",
    "the model across each of those runs. For example, we can call evaluate model() a total of 10\n",
    "times. This will result in a population of model evaluation scores that must be summarized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">#1: 89.990\n",
      ">#2: 86.563\n",
      ">#3: 87.886\n",
      ">#4: 90.159\n",
      ">#5: 89.583\n",
      ">#6: 90.227\n",
      ">#7: 91.381\n",
      ">#8: 90.872\n",
      ">#9: 91.110\n",
      ">#10: 90.635\n",
      "[89.98982310295105, 86.56260371208191, 87.88598775863647, 90.15948176383972, 89.58262801170349, 90.22734761238098, 91.3810670375824, 90.87207317352295, 91.10960364341736, 90.63454270362854]\n",
      "Accuracy: 89.841% (+/-1.435)\n"
     ]
    }
   ],
   "source": [
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seen how to load the data and fit a 1D CNN model, we can investigate\n",
    "whether we can further lift the skill of the model with some hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will tune the model in an effort to further improve performance on the\n",
    "problem. We will look at three main areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Preparation\n",
    "2. Number of Filters\n",
    "3. Size of Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we did not perform any data preparation. We used the data as-is. Each\n",
    "of the main sets of data (body acceleration, body gyroscopic, and total acceleration) have been\n",
    "scaled to the range -1, 1. \n",
    "\n",
    "**It is not clear if the data was scaled per-subject or across all subjects**.\n",
    "One possible transform that may result in an improvement is to standardize the observations\n",
    "prior to fitting a model.\n",
    "\n",
    "Standardization refers to shifting the distribution of each variable such that it has a mean of\n",
    "zero and a standard deviation of 1. \n",
    "\n",
    "It really only makes sense if the distribution of each variable\n",
    "is Gaussian.\n",
    "\n",
    "We can quickly check the distribution of each variable by plotting a histogram of\n",
    "each variable in the training dataset. A minor difficulty in this is that the data has been split\n",
    "into windows of 128 time steps, with a 50% overlap. Therefore, in order to get a fair idea of the\n",
    "data distribution, we must first remove the duplicated observations (the overlap), then remove\n",
    "the windowing of the data.\n",
    "\n",
    "We can do this using NumPy, first slicing the array and only keeping the second half of each\n",
    "window, then flattening the windows into a long vector for each variable. This is quick and dirty\n",
    "and does mean that we lose the data in the first half of the first window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove overlap\n",
    "#\tcut = int(trainX.shape[1] / 2)\n",
    "#\tlongX = trainX[:, -cut:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example of loading the data, flattening it, and plotting a histogram for each\n",
    "of the nine variables is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a histogram of each variable in the dataset\n",
    "def plot_variable_distributions(trainX):\n",
    "\t# remove overlap\n",
    "\tcut = int(trainX.shape[1] / 2)\n",
    "\tlongX = trainX[:, -cut:, :]\n",
    "\t# flatten windows\n",
    "\tlongX = longX.reshape((longX.shape[0] * longX.shape[1], longX.shape[2]))\n",
    "\tpyplot.figure()\n",
    "\tfor i in range(longX.shape[1]):\n",
    "\t\t# create figure\n",
    "\t\tax = pyplot.subplot(longX.shape[1], 1, i+1)\n",
    "\t\tax.set_xlim(-1, 1)\n",
    "\t\t# create histogram\n",
    "\t\tpyplot.hist(longX[:, i], bins=100)\n",
    "\t\t# simplify axis remove clutter\n",
    "\t\tpyplot.yticks([])\n",
    "\t\tpyplot.xticks([-1,0,1])\n",
    "\tpyplot.show()\n",
    "\n",
    "# load data\n",
    "trainX, trainy, testX, testy = load_dataset()\n",
    "# plot histograms\n",
    "plot_variable_distributions(trainX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates a figure with nine histogram plots, **one for each variable in\n",
    "the training dataset**. The order of the plots matches the order in which the data was loaded,\n",
    "specifically:\n",
    "\n",
    "1. Total Acceleration x\n",
    "2. Total Acceleration y\n",
    "3. Total Acceleration z\n",
    "4. Body Acceleration x\n",
    "5. Body Acceleration y\n",
    "6. Body Acceleration z\n",
    "7. Body Gyroscope x\n",
    "8. Body Gyroscope y\n",
    "9. Body Gyroscope z\n",
    "\n",
    "We can see that each variable has a Gaussian-like distribution, except perhaps the first\n",
    "variable (Total Acceleration x). \n",
    "\n",
    "The distributions of total acceleration data is flatter than the\n",
    "body data, which is more pointed. We could explore using a power transform on the data to\n",
    "make the distributions more Gaussian, although this is left as an exercise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data is sufficiently Gaussian-like to explore whether a standardization transform will\n",
    "help the model extract salient signal from the raw observations**. \n",
    "\n",
    "The function below named scale data() can be used to standardize the data prior to fitting and evaluating the model.The StandardScaler scikit-learn class will be used to perform the transform. \n",
    "\n",
    "It is first fit on the training data (e.g. to find the mean and standard deviation for each variable), then applied to the train and test sets. \n",
    "\n",
    "The standardization is optional, so we can apply the process and compare the results to the same code path without the standardization in a controlled experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "def scale_data(trainX, testX, standardize):\n",
    "\t# remove overlap\n",
    "\tcut = int(trainX.shape[1] / 2)\n",
    "\tlongX = trainX[:, -cut:, :]\n",
    "\t# flatten windows\n",
    "\tlongX = longX.reshape((longX.shape[0] * longX.shape[1], longX.shape[2]))\n",
    "\t# flatten train and test\n",
    "\tflatTrainX = trainX.reshape((trainX.shape[0] * trainX.shape[1], trainX.shape[2]))\n",
    "\tflatTestX = testX.reshape((testX.shape[0] * testX.shape[1], testX.shape[2]))\n",
    "\t# standardize\n",
    "\tif standardize:\n",
    "\t\ts = StandardScaler()\n",
    "\t\t# fit on training data\n",
    "\t\ts.fit(longX)\n",
    "\t\t# apply to training and test data\n",
    "\t\tlongX = s.transform(longX)\n",
    "\t\tflatTrainX = s.transform(flatTrainX)\n",
    "\t\tflatTestX = s.transform(flatTestX)\n",
    "\t# reshape\n",
    "\tflatTrainX = flatTrainX.reshape((trainX.shape))\n",
    "\tflatTestX = flatTestX.reshape((testX.shape))\n",
    "\treturn flatTrainX, flatTestX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can update the evaluate model() function to take a parameter, then use this parameter\n",
    "to decide whether or not to perform the standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy, param):\n",
    "\tverbose, epochs, batch_size = 0, 10, 32\n",
    "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\t# scale data\n",
    "\ttrainX, testX = scale_data(trainX, testX, param)\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv1D(64, 3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "\tmodel.add(Conv1D(64, 3, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(MaxPooling1D())\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also update the run experiment() to repeat the experiment 10 times for each parameter; in this case, only two parameters will be evaluated [False, True] for no standardization\n",
    "and standardization respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">p=False #1: 89.277\n",
      ">p=False #2: 89.752\n",
      ">p=False #3: 87.988\n",
      ">p=False #4: 92.467\n",
      ">p=False #5: 89.718\n",
      ">p=False #6: 90.974\n",
      ">p=False #7: 91.449\n",
      ">p=False #8: 91.449\n",
      ">p=False #9: 90.329\n",
      ">p=False #10: 91.110\n",
      ">p=True #1: 92.162\n",
      ">p=True #2: 90.058\n",
      ">p=True #3: 90.974\n",
      ">p=True #4: 92.467\n",
      ">p=True #5: 91.890\n",
      ">p=True #6: 93.315\n",
      ">p=True #7: 90.024\n",
      ">p=True #8: 91.619\n",
      ">p=True #9: 92.331\n",
      ">p=True #10: 91.585\n",
      "[[89.27723169326782, 89.75229263305664, 87.98778653144836, 92.46691465377808, 89.71835970878601, 90.97387194633484, 91.44893288612366, 91.44893288612366, 90.32914638519287, 91.10960364341736], [92.16151833534241, 90.05768299102783, 90.97387194633484, 92.46691465377808, 91.89005494117737, 93.31523776054382, 90.0237500667572, 91.6185975074768, 92.33118295669556, 91.58466458320618]] [False, True]\n",
      "Param=False: 90.451% (+/-1.235)\n",
      "Param=True: 91.642% (+/-0.993)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize scores\n",
    "def summarize_results(scores, params):\n",
    "\tprint(scores, params)\n",
    "\t# summarize mean and standard deviation\n",
    "\tfor i in range(len(scores)):\n",
    "\t\tm, s = mean(scores[i]), std(scores[i])\n",
    "\t\tprint('Param=%s: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    "\t# boxplot of scores\n",
    "\tpyplot.boxplot(scores, labels=params)\n",
    "\tpyplot.savefig('exp_cnn_standardize.png')\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(params, repeats=10):\n",
    "\t# load data\n",
    "\ttrainX, trainy, testX, testy = load_dataset()\n",
    "\t# test each parameter\n",
    "\tall_scores = list()\n",
    "\tfor p in params:\n",
    "\t\t# repeat experiment\n",
    "\t\tscores = list()\n",
    "\t\tfor r in range(repeats):\n",
    "\t\t\tscore = evaluate_model(trainX, trainy, testX, testy, p)\n",
    "\t\t\tscore = score * 100.0\n",
    "\t\t\tprint('>p=%s #%d: %.3f' % (p, r+1, score))\n",
    "\t\t\tscores.append(score)\n",
    "\t\tall_scores.append(scores)\n",
    "\t# summarize results\n",
    "\tsummarize_results(all_scores, params)\n",
    "\n",
    "# run the experiment\n",
    "n_params = [False, True]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example may take a while, depending on your hardware. \n",
    "\n",
    "The performance is printed for each evaluated model. At the end of the run, the performance of each of the tested configurations is summarized showing the mean and the standard deviation. \n",
    "\n",
    "We can see that it does look like standardizing the dataset prior to modeling does result in a small lift in performance from about 90.4% accuracy (close to what we saw in the previous section) to about\n",
    "91.6% accuracy.\n",
    "\n",
    "\n",
    "**Note**: Given the stochastic nature of the algorithm, your specific results may vary. Consider\n",
    "running the example a few times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **box and whisker plot** of the results is also created. \n",
    "\n",
    "This allows the two samples of results to be compared **in a nonparametric way**. \n",
    "\n",
    "We can see that the distribution of results with standardization is quite different from\n",
    "the distribution of results without standardization. **This is likely a real effect**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an experimental framework, we can explore varying other hyperparameters\n",
    "of the model. \n",
    "\n",
    "An important hyperparameter for the CNN is **the number of filter maps**. \n",
    "\n",
    "We can experiment with a range of different values, from less to many more than the 64 used in the\n",
    "first model that we developed. Specifically, we will try the following numbers of feature maps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same code from the previous section and update the evaluate model()\n",
    "function to use the provided parameter as the number of filters in the Conv1D layers. \n",
    "\n",
    "We can also update the summarize results() function to save the box plot as exp cnn filters.png.\n",
    "The complete code example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">p=8 #1: 89.175\n",
      ">p=8 #2: 89.277\n",
      ">p=8 #3: 87.988\n",
      ">p=8 #4: 85.714\n",
      ">p=8 #5: 90.499\n",
      ">p=8 #6: 88.191\n",
      ">p=8 #7: 89.786\n",
      ">p=8 #8: 89.277\n",
      ">p=8 #9: 88.565\n",
      ">p=8 #10: 85.748\n",
      ">p=16 #1: 91.211\n",
      ">p=16 #2: 90.533\n",
      ">p=16 #3: 89.481\n",
      ">p=16 #4: 89.074\n",
      ">p=16 #5: 89.990\n",
      ">p=16 #6: 90.024\n",
      ">p=16 #7: 89.481\n",
      ">p=16 #8: 90.092\n",
      ">p=16 #9: 88.429\n",
      ">p=16 #10: 88.904\n",
      ">p=32 #1: 91.008\n",
      ">p=32 #2: 90.465\n",
      ">p=32 #3: 90.499\n",
      ">p=32 #4: 89.990\n",
      ">p=32 #5: 90.465\n",
      ">p=32 #6: 91.211\n",
      ">p=32 #7: 88.633\n",
      ">p=32 #8: 90.329\n",
      ">p=32 #9: 90.227\n",
      ">p=32 #10: 91.381\n",
      ">p=64 #1: 92.874\n",
      ">p=64 #2: 89.311\n",
      ">p=64 #3: 91.042\n",
      ">p=64 #4: 90.533\n",
      ">p=64 #5: 87.038\n",
      ">p=64 #6: 90.092\n",
      ">p=64 #7: 91.313\n",
      ">p=64 #8: 90.126\n",
      ">p=64 #9: 91.686\n",
      ">p=64 #10: 89.990\n",
      ">p=128 #1: 90.431\n",
      ">p=128 #2: 92.128\n",
      ">p=128 #3: 88.056\n",
      ">p=128 #4: 91.245\n",
      ">p=128 #5: 90.397\n",
      ">p=128 #6: 89.345\n",
      ">p=128 #7: 92.637\n",
      ">p=128 #8: 91.686\n",
      ">p=128 #9: 91.449\n",
      ">p=128 #10: 91.551\n",
      ">p=256 #1: 90.159\n",
      ">p=256 #2: 92.467\n",
      ">p=256 #3: 91.415\n",
      ">p=256 #4: 91.042\n",
      ">p=256 #5: 91.890\n",
      ">p=256 #6: 90.838\n",
      ">p=256 #7: 90.431\n",
      ">p=256 #8: 91.042\n",
      ">p=256 #9: 91.720\n",
      ">p=256 #10: 91.076\n",
      "[[89.17543292045593, 89.27723169326782, 87.98778653144836, 85.71428656578064, 90.49881100654602, 88.19137811660767, 89.78622555732727, 89.27723169326782, 88.5646402835846, 85.74821949005127], [91.21140241622925, 90.53274393081665, 89.4808292388916, 89.07363414764404, 89.98982310295105, 90.0237500667572, 89.4808292388916, 90.09161591529846, 88.42890858650208, 88.9039695262909], [91.00780487060547, 90.46487808227539, 90.49881100654602, 89.98982310295105, 90.46487808227539, 91.21140241622925, 88.63250613212585, 90.32914638519287, 90.22734761238098, 91.3810670375824], [92.87410974502563, 89.31116461753845, 91.0417377948761, 90.53274393081665, 87.03766465187073, 90.09161591529846, 91.31320118904114, 90.12554883956909, 91.68646335601807, 89.98982310295105], [90.43094515800476, 92.12758541107178, 88.05565237998962, 91.24533534049988, 90.39701223373413, 89.34509754180908, 92.63657927513123, 91.68646335601807, 91.44893288612366, 91.55073165893555], [90.15948176383972, 92.46691465377808, 91.41499996185303, 91.0417377948761, 91.89005494117737, 90.83814024925232, 90.43094515800476, 91.0417377948761, 91.7203962802887, 91.07567071914673]] [8, 16, 32, 64, 128, 256]\n",
      "Param=8: 88.422% (+/-1.515)\n",
      "Param=16: 89.722% (+/-0.778)\n",
      "Param=32: 90.421% (+/-0.730)\n",
      "Param=64: 90.400% (+/-1.479)\n",
      "Param=128: 90.892% (+/-1.303)\n",
      "Param=256: 91.208% (+/-0.653)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy, n_filters):\n",
    "\tverbose, epochs, batch_size = 0, 10, 32\n",
    "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv1D(n_filters, 3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "\tmodel.add(Conv1D(n_filters, 3, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(MaxPooling1D())\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\treturn accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores, params):\n",
    "\tprint(scores, params)\n",
    "\t# summarize mean and standard deviation\n",
    "\tfor i in range(len(scores)):\n",
    "\t\tm, s = mean(scores[i]), std(scores[i])\n",
    "\t\tprint('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    "\t# boxplot of scores\n",
    "\tpyplot.boxplot(scores, labels=params)\n",
    "\tpyplot.savefig('exp_cnn_filters.png')\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(params, repeats=10):\n",
    "\t# load data\n",
    "\ttrainX, trainy, testX, testy = load_dataset()\n",
    "\t# test each parameter\n",
    "\tall_scores = list()\n",
    "\tfor p in params:\n",
    "\t\t# repeat experiment\n",
    "\t\tscores = list()\n",
    "\t\tfor r in range(repeats):\n",
    "\t\t\tscore = evaluate_model(trainX, trainy, testX, testy, p)\n",
    "\t\t\tscore = score * 100.0\n",
    "\t\t\tprint('>p=%d #%d: %.3f' % (p, r+1, score))\n",
    "\t\t\tscores.append(score)\n",
    "\t\tall_scores.append(scores)\n",
    "\t# summarize results\n",
    "\tsummarize_results(all_scores, params)\n",
    "\n",
    "# run the experiment\n",
    "n_params = [8, 16, 32, 64, 128, 256]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the kernel is another important hyperparameter of the 1D CNN to tune. **The kernel\n",
    "size controls the number of time steps consider in each read of the input sequence**, that is then\n",
    "projected onto the feature map (via the convolutional process). \n",
    "\n",
    "**A large kernel size means a less rigorous reading of the data**, but may result in a more generalized snapshot of the input. \n",
    "\n",
    "We can use the same experimental setup and test a suite of different kernel sizes in addition to the default of three time steps. The full list of values is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = [2, 3, 5, 7, 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example tests each kernel size in turn. \n",
    "\n",
    "The results are summarized at the end of the run. We can see a general increase in model performance with the increase in kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">p=2 #1: 90.363\n",
      ">p=2 #2: 90.024\n",
      ">p=2 #3: 90.363\n",
      ">p=2 #4: 90.533\n",
      ">p=2 #5: 89.854\n",
      ">p=2 #6: 89.617\n",
      ">p=2 #7: 89.888\n",
      ">p=2 #8: 88.565\n",
      ">p=2 #9: 89.175\n",
      ">p=2 #10: 90.397\n",
      ">p=3 #1: 91.008\n",
      ">p=3 #2: 90.397\n",
      ">p=3 #3: 90.804\n",
      ">p=3 #4: 91.653\n",
      ">p=3 #5: 90.736\n",
      ">p=3 #6: 90.465\n",
      ">p=3 #7: 88.463\n",
      ">p=3 #8: 90.024\n",
      ">p=3 #9: 90.940\n",
      ">p=3 #10: 90.533\n",
      ">p=5 #1: 92.331\n",
      ">p=5 #2: 90.601\n",
      ">p=5 #3: 90.567\n",
      ">p=5 #4: 90.159\n",
      ">p=5 #5: 90.397\n",
      ">p=5 #6: 91.042\n",
      ">p=5 #7: 89.277\n",
      ">p=5 #8: 91.245\n",
      ">p=5 #9: 91.144\n",
      ">p=5 #10: 90.465\n",
      ">p=7 #1: 92.229\n",
      ">p=7 #2: 91.483\n",
      ">p=7 #3: 91.449\n",
      ">p=7 #4: 89.684\n",
      ">p=7 #5: 92.263\n",
      ">p=7 #6: 92.263\n",
      ">p=7 #7: 91.042\n",
      ">p=7 #8: 91.653\n",
      ">p=7 #9: 90.465\n",
      ">p=7 #10: 91.381\n",
      ">p=11 #1: 93.247\n",
      ">p=11 #2: 93.044\n",
      ">p=11 #3: 90.770\n",
      ">p=11 #4: 91.720\n",
      ">p=11 #5: 91.415\n",
      ">p=11 #6: 92.229\n",
      ">p=11 #7: 91.856\n",
      ">p=11 #8: 90.940\n",
      ">p=11 #9: 92.433\n",
      ">p=11 #10: 90.940\n",
      "[[90.3630793094635, 90.0237500667572, 90.3630793094635, 90.53274393081665, 89.85409140586853, 89.61656093597412, 89.88802433013916, 88.5646402835846, 89.17543292045593, 90.39701223373413], [91.00780487060547, 90.39701223373413, 90.80420732498169, 91.65253043174744, 90.73634147644043, 90.46487808227539, 88.4628415107727, 90.0237500667572, 90.93993902206421, 90.53274393081665], [92.33118295669556, 90.60060977935791, 90.56667685508728, 90.15948176383972, 90.39701223373413, 91.0417377948761, 89.27723169326782, 91.24533534049988, 91.14353656768799, 90.46487808227539], [92.22938418388367, 91.48286581039429, 91.44893288612366, 89.68442678451538, 92.2633171081543, 92.2633171081543, 91.0417377948761, 91.65253043174744, 90.46487808227539, 91.3810670375824], [93.24737191200256, 93.04377436637878, 90.77027440071106, 91.7203962802887, 91.41499996185303, 92.22938418388367, 91.85612201690674, 90.93993902206421, 92.43298172950745, 90.93993902206421]] [2, 3, 5, 7, 11]\n",
      "Param=2: 89.878% (+/-0.590)\n",
      "Param=3: 90.502% (+/-0.795)\n",
      "Param=5: 90.723% (+/-0.759)\n",
      "Param=7: 91.391% (+/-0.787)\n",
      "Param=11: 91.860% (+/-0.830)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy, n_kernel):\n",
    "\tverbose, epochs, batch_size = 0, 15, 32\n",
    "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv1D(64, n_kernel, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "\tmodel.add(Conv1D(64, n_kernel, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(MaxPooling1D())\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\treturn accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores, params):\n",
    "\tprint(scores, params)\n",
    "\t# summarize mean and standard deviation\n",
    "\tfor i in range(len(scores)):\n",
    "\t\tm, s = mean(scores[i]), std(scores[i])\n",
    "\t\tprint('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n",
    "\t# boxplot of scores\n",
    "\tpyplot.boxplot(scores, labels=params)\n",
    "\tpyplot.savefig('exp_cnn_kernel.png')\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(params, repeats=10):\n",
    "\t# load data\n",
    "\ttrainX, trainy, testX, testy = load_dataset()\n",
    "\t# test each parameter\n",
    "\tall_scores = list()\n",
    "\tfor p in params:\n",
    "\t\t# repeat experiment\n",
    "\t\tscores = list()\n",
    "\t\tfor r in range(repeats):\n",
    "\t\t\tscore = evaluate_model(trainX, trainy, testX, testy, p)\n",
    "\t\t\tscore = score * 100.0\n",
    "\t\t\tprint('>p=%d #%d: %.3f' % (p, r+1, score))\n",
    "\t\t\tscores.append(score)\n",
    "\t\tall_scores.append(scores)\n",
    "\t# summarize results\n",
    "\tsummarize_results(all_scores, params)\n",
    "\n",
    "# run the experiment\n",
    "n_params = [2, 3, 5, 7, 11]\n",
    "run_experiment(n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results suggest a kernel size of 5 might be good with a mean skill of about 91.8%, but\n",
    "perhaps a size of 7 or 11 may also be just as good with a smaller standard deviation.\n",
    "Note: Given the stochastic nature of the algorithm, your specific results may vary. Consider\n",
    "running the example a few times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A box and whisker plot of the results is also created. The results suggest that a larger kernel\n",
    "size does appear to result in better accuracy and that perhaps a kernel size of 7 provides a good\n",
    "balance between good performance and low variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just the beginning of tuning the model, although we have focused on perhaps the\n",
    "more important elements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-headed CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular approach with 1D CNNs is to have a multi-headed model, where each head of\n",
    "the model reads the input time steps using a different sized kernel.\n",
    "\n",
    "For example, a three-headed model may have three different kernel sizes of 3, 5, 11, allowing the model to read and interpret the sequence data at three different resolutions. The interpretations from all three heads are then concatenated within the model and interpreted by a fully-connected layer before a prediction is made.\n",
    "\n",
    "We can implement a multi-headed 1D CNN using the Keras functional API. \n",
    "\n",
    "We can see that each head of the model is the same structure, although the kernel size\n",
    "is varied. \n",
    "\n",
    "The three heads then feed into a single merge layer before being interpreted prior to\n",
    "making a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">#1: 91.754\n",
      ">#2: 92.738\n",
      ">#3: 93.213\n",
      ">#4: 92.060\n",
      ">#5: 93.587\n",
      ">#6: 92.263\n",
      ">#7: 91.347\n",
      ">#8: 93.112\n",
      ">#9: 91.483\n",
      ">#10: 91.042\n",
      "[91.75432920455933, 92.73837804794312, 93.21343898773193, 92.05971956253052, 93.58670115470886, 92.2633171081543, 91.34713411331177, 93.11164021492004, 91.48286581039429, 91.0417377948761]\n",
      "Accuracy: 92.260% (+/-0.827)\n"
     ]
    }
   ],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "\tverbose, epochs, batch_size = 0, 10, 32\n",
    "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    " \t# head 1\n",
    "\tinputs1 = Input(shape=(n_timesteps,n_features))\n",
    "\tconv1 = Conv1D(64, 3, activation='relu')(inputs1)\n",
    "\tdrop1 = Dropout(0.5)(conv1)\n",
    "\tpool1 = MaxPooling1D()(drop1)\n",
    "\tflat1 = Flatten()(pool1)\n",
    "\t# head 2\n",
    "\tinputs2 = Input(shape=(n_timesteps,n_features))\n",
    "\tconv2 = Conv1D(64, 5, activation='relu')(inputs2)\n",
    "\tdrop2 = Dropout(0.5)(conv2)\n",
    "\tpool2 = MaxPooling1D()(drop2)\n",
    "\tflat2 = Flatten()(pool2)\n",
    "\t# head 3\n",
    "\tinputs3 = Input(shape=(n_timesteps,n_features))\n",
    "\tconv3 = Conv1D(64, 11, activation='relu')(inputs3)\n",
    "\tdrop3 = Dropout(0.5)(conv3)\n",
    "\tpool3 = MaxPooling1D()(drop3)\n",
    "\tflat3 = Flatten()(pool3)\n",
    "\t# merge\n",
    "\tmerged = concatenate([flat1, flat2, flat3])\n",
    "\t# interpretation\n",
    "\tdense1 = Dense(100, activation='relu')(merged)\n",
    "\toutputs = Dense(n_outputs, activation='softmax')(dense1)\n",
    "\tmodel = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "\t# save a plot of the model\n",
    "\tplot_model(model, show_shapes=True, to_file='multiheaded.png')\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "\tmodel.fit([trainX,trainX,trainX], trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate([testX,testX,testX], testy, batch_size=batch_size, verbose=0)\n",
    "\treturn accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "\tprint(scores)\n",
    "\tm, s = mean(scores), std(scores)\n",
    "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "\t# load data\n",
    "\ttrainX, trainy, testX, testy = load_dataset()\n",
    "\t# repeat experiment\n",
    "\tscores = list()\n",
    "\tfor r in range(repeats):\n",
    "\t\tscore = evaluate_model(trainX, trainy, testX, testy)\n",
    "\t\tscore = score * 100.0\n",
    "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
    "\t\tscores.append(score)\n",
    "\t# summarize results\n",
    "\tsummarize_results(scores)\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the model is created, a plot of the network architecture is created; provided below, it\n",
    "gives a clear idea of how the constructed model fits together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other aspects of the model could be varied across the heads, such as the number of filters or\n",
    "even the preparation of the data itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example prints the performance of the model each repeat of the experiment and\n",
    "then summarizes the estimated score as the mean and standard deviation, as we did in the first\n",
    "case with the simple 1D CNN. \n",
    "\n",
    "We can see that the average performance of the model is about\n",
    "92.2% classification accuracy with a standard deviation of about 0.8. \n",
    "\n",
    "This example may be used\n",
    "as the basis for exploring a variety of other models that vary different model hyperparameters\n",
    "and even different data preparation schemes across the input heads.\n",
    "\n",
    "**It would not be an apples-to-apples comparison to compare this result with a single-headed\n",
    "CNN given the relative tripling of the resources in this model**. Perhaps an apples-to-apples\n",
    "comparison would be a model with the same architecture and the same number of filters across\n",
    "each input head of the model.\n",
    "\n",
    "**Note**: Given the stochastic nature of the algorithm, your specific results may vary. Consider\n",
    "running the example a few times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('metodos')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "7a264cf02235baedc191a9dec9b9e97db7af4c090365dde23adf9d2150b99a47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
